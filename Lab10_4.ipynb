{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uSVZ2RzgJxm"
   },
   "source": [
    "이번 LAB은 퀴즈로만 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF_maLR0gHMY"
   },
   "source": [
    "Q1. 다음과 같이 conv1 의 이름으로 convolution layer 필터를 만들어 주고 inputs를 넣어주었습니다.\n",
    "\n",
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "\n",
    "inputs = (A,B,C,D)\n",
    "\n",
    "output = conv1(inputs)\n",
    "\n",
    "위 코드에서 inputs의 형태로 알맞은 것을 서술하시오.\n",
    "(Height, Channel, Width, Batch size)\n",
    "\n",
    "A : Batch size\n",
    "\n",
    "B : Channel\n",
    "\n",
    "C : Height\n",
    "\n",
    "D : Width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzfv6owvhFLm"
   },
   "source": [
    "Q2. Convolution의 output image size를 구하시오.\n",
    "\n",
    "input image size =  32 X 32\n",
    "\n",
    "filter size = 5 X 5\n",
    "\n",
    "stride = 1\n",
    "\n",
    "padding = 2\n",
    "\n",
    "=> output image size = 32 X 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrwFeiSYhaU4"
   },
   "source": [
    "Q3. Convolution의 output image size를 구하시오.\n",
    "\n",
    "input image size =  32 X 64\n",
    "\n",
    "filter size = 5 X 5\n",
    "\n",
    "stride = 1\n",
    "\n",
    "padding = 0\n",
    "\n",
    "=> output image size = 28 X 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v91w87NcmNgg"
   },
   "source": [
    "Q4. 출력 결과는?\n",
    "\n",
    "inputs = torch.Tensor(1,1,32,32)\n",
    "\n",
    "conv1 = torch.nn.Conv2d(1,1,(5,5), stride = 1, padding = 2)\n",
    "\n",
    "output = conv1(inputs)\n",
    "\n",
    "print(output.size())\n",
    "\n",
    "=> torch.Size([1,1,32,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ynqfr96OhbxA"
   },
   "source": [
    "Q5. 채널이 8인 42x42 input 이미지와 5x5의 16채널 필터를 \"stride=1\"로 convolution 연산을 하되, input과 같은 크기의 ouput 결과를 가져오도록 하려고 한다. 이 때, 얼마의 padding을 주어야 하는가?\n",
    "\n",
    "padding = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs0MKwgiYcj"
   },
   "source": [
    "Q6. Convolution layer에 3X3 필터와 stride=1을 사용하여 더 적은 파라미터를 통해 학습의 효율성을 높인 CNN 모델은?\n",
    "\n",
    "=> VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnSa8FHbjd27"
   },
   "source": [
    "Q7. Residual block을 통한 skip connection으로 연산량을 줄이고 gradient vanishing, exploding 문제를 해결한 CNN 모델은?\n",
    "\n",
    "=> ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaSOqXQBj4v8"
   },
   "source": [
    "Q8. GoogleNet에서 활용되는 인셉션 모듈에서 (1,1) 사이즈의 필터를 사용하는 이유는?\n",
    "\n",
    "=> 차원 축소를 위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyfEJgjMkz0_"
   },
   "source": [
    "Q9. GoogleNet에서 사용하는 auxiliary classifier의 역할과 장점은?\n",
    "\n",
    "=> 중간에 auxiliary classifier를 배치하여 Backpropagation한다.\n",
    "\n",
    "Vanishing gradient 문제를 줄일 수 있는 장점이 있다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab10_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
